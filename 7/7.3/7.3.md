<hr>
<div align="center">
 
[**🔙 Atrás**](../7.2/7.2.md) | [**📜 Índice**](../../README.md)

</div>
<hr>

# 7.3. Carga Masiva de Datos

## Estrategia para carga masiva de registros

Con el objetivo de optimizar el ingreso de datos en volumen para pruebas o implementación en entornos reales, se propuso el uso de carga masiva mediante archivos `.csv` utilizando herramientas externas compatibles con PostgreSQL, como **pgAdmin**, **DBeaver**, etc.

### Herramientas y métodos utilizados

1. **Generación de datos con Mockaroo**  
   Se utilizaron herramientas como [Mockaroo](https://www.mockaroo.com/) y/o [ChatGPT](https://chatgpt.com/) para simular registros realistas exportables en formato `.csv`, lo cual permitió poblar tablas como `Usuarios`, `Induccion`, `MaterialInduccion`, entre otras, sin necesidad de escribir manualmente los datos.

2. **Importación desde pgAdmin**  
   Desde pgAdmin, se utilizó la opción **Import/Export Data** dentro de cada tabla para importar archivos `.csv`. El proceso consiste en:
   - Click derecho sobre la tabla > Import/Export.
   - Seleccionar archivo `.csv`.
   - Especificar columnas y delimitadores (usualmente coma `,`).
   - Ejecutar la importación.

### Consideraciones importantes

- Se validó que todos los archivos `.csv` estén codificados en UTF-8 para evitar errores con caracteres especiales.
- Se aseguró que los archivos coincidan en estructura (número y orden de columnas) con la definición de las tablas.
- En tablas con claves foráneas, se respetó el orden de carga para evitar errores de integridad referencial.
